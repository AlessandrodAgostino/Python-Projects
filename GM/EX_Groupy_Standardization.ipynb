{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The exercise - Grouped Standardizer\n",
    "\n",
    "Our goal might be to implement a groupby standardizer.\n",
    "\n",
    "a standardizer subtract the average of one or more columns, and divide the data by their standard deviation.\n",
    "\n",
    "The standard **standardizer** does use the whole data average, but we might want to do this operation separatedly on different groups, for example by country.\n",
    "\n",
    "Assuming that all the groupby categories are present in the traning data, try to implement it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv'\n",
    "iris = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best attempt 'till now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I apply `trasform` to all the **DF** it works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.019004</td>\n",
       "      <td>-1.340227</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.143017</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>-1.340227</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.385353</td>\n",
       "      <td>0.328414</td>\n",
       "      <td>-1.397064</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.506521</td>\n",
       "      <td>0.098217</td>\n",
       "      <td>-1.283389</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.021849</td>\n",
       "      <td>1.249201</td>\n",
       "      <td>-1.340227</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0     -0.900681     1.019004     -1.340227    -1.315444\n",
       "1     -1.143017    -0.131979     -1.340227    -1.315444\n",
       "2     -1.385353     0.328414     -1.397064    -1.315444\n",
       "3     -1.506521     0.098217     -1.283389    -1.315444\n",
       "4     -1.021849     1.249201     -1.340227    -1.315444"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv(url)\n",
    "#On the entrie df w/o grouping it works well\n",
    "iris = iris.iloc[:,:-1].transform(lambda x: (x - np.mean(x))/np.std(x))\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I manually extract the group from the `groupby` output and trasform it it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.269382</td>\n",
       "      <td>0.191870</td>\n",
       "      <td>-0.360636</td>\n",
       "      <td>-0.440924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.303771</td>\n",
       "      <td>-1.140559</td>\n",
       "      <td>-0.360636</td>\n",
       "      <td>-0.440924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.876924</td>\n",
       "      <td>-0.607588</td>\n",
       "      <td>-0.942306</td>\n",
       "      <td>-0.440924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.163501</td>\n",
       "      <td>-0.874073</td>\n",
       "      <td>0.221035</td>\n",
       "      <td>-0.440924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.017195</td>\n",
       "      <td>0.458355</td>\n",
       "      <td>-0.360636</td>\n",
       "      <td>-0.440924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0      0.269382     0.191870     -0.360636    -0.440924\n",
       "1     -0.303771    -1.140559     -0.360636    -0.440924\n",
       "2     -0.876924    -0.607588     -0.942306    -0.440924\n",
       "3     -1.163501    -0.874073      0.221035    -0.440924\n",
       "4     -0.017195     0.458355     -0.360636    -0.440924"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv(url)\n",
    "#If I manually extract the group it work perfectly\n",
    "setosa = iris.groupby('species').get_group('setosa')\n",
    "setosa = setosa._get_numeric_data().transform(lambda x: (x - np.mean(x))/np.std(x))\n",
    "setosa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.,  0., 29.,  0.,  7.,  0.,  7.,  0.,  1.,  1.]),\n",
       " array([-1.39945388, -0.92018885, -0.44092382,  0.0383412 ,  0.51760623,\n",
       "         0.99687125,  1.47613628,  1.95540131,  2.43466633,  2.91393136,\n",
       "         3.39319638]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(ncols=4, figsize=(12,2))\n",
    "axes[0].hist('sepal_length', data=setosa)\n",
    "axes[1].hist('sepal_width', data=setosa)\n",
    "axes[2].hist('petal_length', data=setosa)\n",
    "axes[3].hist('petal_width', data=setosa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the moment that I try to apply the `trasform` on every groups iterating them it doesn't modify the original **DF** `iris`.\n",
    "Does it modify a certain copy? like assignemt y value and not by reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "0             5.1          3.5           1.4          0.2      setosa\n",
       "1             4.9          3.0           1.4          0.2      setosa\n",
       "2             4.7          3.2           1.3          0.2      setosa\n",
       "3             4.6          3.1           1.5          0.2      setosa\n",
       "4             5.0          3.6           1.4          0.2      setosa\n",
       "50            7.0          3.2           4.7          1.4  versicolor\n",
       "51            6.4          3.2           4.5          1.5  versicolor\n",
       "52            6.9          3.1           4.9          1.5  versicolor\n",
       "53            5.5          2.3           4.0          1.3  versicolor\n",
       "54            6.5          2.8           4.6          1.5  versicolor\n",
       "100           6.3          3.3           6.0          2.5   virginica\n",
       "101           5.8          2.7           5.1          1.9   virginica\n",
       "102           7.1          3.0           5.9          2.1   virginica\n",
       "103           6.3          2.9           5.6          1.8   virginica\n",
       "104           6.5          3.0           5.8          2.2   virginica"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv(url)\n",
    "iris = iris.groupby('species')\n",
    "for key, group in iris:\n",
    "    group = group._get_numeric_data().transform(lambda x: (x - np.mean(x))/np.std(x))\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to extract through location \n",
    "I try to extract numerical column and the categorical column to be used to make the groupby.\n",
    "I fail trying to merge those Dataframe because they do not share any index or column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_number = np.vectorize(lambda x: is_numeric_dtype(x))\n",
    "num_cols = is_number(iris.dtypes) #Extracting the booleand mask for numerical columns in the DataFrame\n",
    "numeric_columns_df = iris.iloc[:,num_cols] #Extracting numerical columns\n",
    "grouping_column_df = iris.loc[:,'species'] #Ectracting the Column I want to use to make the grouping\n",
    "\n",
    "#I DON'T KNOW OVER WHICH VALUE I SHOULD MANAGE THE MERGING\n",
    "#pd.merge(grouping_column_df, numeric_columns_df, on='index', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is good but there isn't the *'species'* column\n",
    "If I do this way I lose the information about the species.\n",
    "If I try to make the groupby using \"as_index = False\" it raises error because it keepS a non numerical column which it is not compatible with the lambda function used to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.269382</td>\n",
       "      <td>0.191870</td>\n",
       "      <td>-0.360636</td>\n",
       "      <td>-0.440924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.303771</td>\n",
       "      <td>-1.140559</td>\n",
       "      <td>-0.360636</td>\n",
       "      <td>-0.440924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.876924</td>\n",
       "      <td>-0.607588</td>\n",
       "      <td>-0.942306</td>\n",
       "      <td>-0.440924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.163501</td>\n",
       "      <td>-0.874073</td>\n",
       "      <td>0.221035</td>\n",
       "      <td>-0.440924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.017195</td>\n",
       "      <td>0.458355</td>\n",
       "      <td>-0.360636</td>\n",
       "      <td>-0.440924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0      0.269382     0.191870     -0.360636    -0.440924\n",
       "1     -0.303771    -1.140559     -0.360636    -0.440924\n",
       "2     -0.876924    -0.607588     -0.942306    -0.440924\n",
       "3     -1.163501    -0.874073      0.221035    -0.440924\n",
       "4     -0.017195     0.458355     -0.360636    -0.440924"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdz_iris = iris.groupby('species').apply(lambda x: (x - np.mean(x))/np.std(x))\n",
    "stdz_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.570596e-15</td>\n",
       "      <td>-9.858780e-16</td>\n",
       "      <td>-2.590520e-17</td>\n",
       "      <td>8.200847e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.003350e+00</td>\n",
       "      <td>1.003350e+00</td>\n",
       "      <td>1.003350e+00</td>\n",
       "      <td>1.003350e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.681541e+00</td>\n",
       "      <td>-3.005959e+00</td>\n",
       "      <td>-2.708582e+00</td>\n",
       "      <td>-2.302404e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.472601e-01</td>\n",
       "      <td>-6.075875e-01</td>\n",
       "      <td>-7.414799e-01</td>\n",
       "      <td>-4.634232e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.719459e-02</td>\n",
       "      <td>8.143950e-02</td>\n",
       "      <td>8.785611e-02</td>\n",
       "      <td>-1.328122e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.559584e-01</td>\n",
       "      <td>7.078972e-01</td>\n",
       "      <td>7.074045e-01</td>\n",
       "      <td>8.266064e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.275417e+00</td>\n",
       "      <td>2.590242e+00</td>\n",
       "      <td>2.547718e+00</td>\n",
       "      <td>3.393196e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length   sepal_width  petal_length   petal_width\n",
       "count  1.500000e+02  1.500000e+02  1.500000e+02  1.500000e+02\n",
       "mean   1.570596e-15 -9.858780e-16 -2.590520e-17  8.200847e-16\n",
       "std    1.003350e+00  1.003350e+00  1.003350e+00  1.003350e+00\n",
       "min   -2.681541e+00 -3.005959e+00 -2.708582e+00 -2.302404e+00\n",
       "25%   -6.472601e-01 -6.075875e-01 -7.414799e-01 -4.634232e-01\n",
       "50%   -1.719459e-02  8.143950e-02  8.785611e-02 -1.328122e-01\n",
       "75%    5.559584e-01  7.078972e-01  7.074045e-01  8.266064e-01\n",
       "max    2.275417e+00  2.590242e+00  2.547718e+00  3.393196e+00"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdz_iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-274483dda683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstdz_iris\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Very poor plots\n",
    "fig, axes = plt.subplots(ncols=4, figsize=(12,2))\n",
    "axes[0].hist('sepal_length', data=stdz_iris)\n",
    "axes[1].hist('sepal_width', data=stdz_iris)\n",
    "axes[2].hist('petal_length', data=stdz_iris)\n",
    "axes[3].hist('petal_width', data=stdz_iris)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt going through different groups\n",
    "I would have liked to apply the lambda function to every group but I wasn't able to obtain nothing.\n",
    " * what is the difference between `pandas.core.frame.DataFrame` and normal `pandas.DataFrame`???\n",
    " * Why I can't see any modifiction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "0             5.1          3.5           1.4          0.2      setosa\n",
       "1             4.9          3.0           1.4          0.2      setosa\n",
       "2             4.7          3.2           1.3          0.2      setosa\n",
       "3             4.6          3.1           1.5          0.2      setosa\n",
       "4             5.0          3.6           1.4          0.2      setosa\n",
       "50            7.0          3.2           4.7          1.4  versicolor\n",
       "51            6.4          3.2           4.5          1.5  versicolor\n",
       "52            6.9          3.1           4.9          1.5  versicolor\n",
       "53            5.5          2.3           4.0          1.3  versicolor\n",
       "54            6.5          2.8           4.6          1.5  versicolor\n",
       "100           6.3          3.3           6.0          2.5   virginica\n",
       "101           5.8          2.7           5.1          1.9   virginica\n",
       "102           7.1          3.0           5.9          2.1   virginica\n",
       "103           6.3          2.9           5.6          1.8   virginica\n",
       "104           6.5          3.0           5.8          2.2   virginica"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_iris = iris.groupby('species', as_index=False)\n",
    "for key, group in gr_iris:\n",
    "    print(type(group))\n",
    "    group = group._get_numeric_data().apply(lambda x: (x - np.mean(x))/np.std(x)) #Why it's not modified ?????\n",
    "gr_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "0             5.1          3.5           1.4          0.2      setosa\n",
       "1             4.9          3.0           1.4          0.2      setosa\n",
       "2             4.7          3.2           1.3          0.2      setosa\n",
       "3             4.6          3.1           1.5          0.2      setosa\n",
       "4             5.0          3.6           1.4          0.2      setosa\n",
       "50            7.0          3.2           4.7          1.4  versicolor\n",
       "51            6.4          3.2           4.5          1.5  versicolor\n",
       "52            6.9          3.1           4.9          1.5  versicolor\n",
       "53            5.5          2.3           4.0          1.3  versicolor\n",
       "54            6.5          2.8           4.6          1.5  versicolor\n",
       "100           6.3          3.3           6.0          2.5   virginica\n",
       "101           5.8          2.7           5.1          1.9   virginica\n",
       "102           7.1          3.0           5.9          2.1   virginica\n",
       "103           6.3          2.9           5.6          1.8   virginica\n",
       "104           6.5          3.0           5.8          2.2   virginica"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_iris = iris.groupby('species', as_index=True)\n",
    "gr_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "0             5.1          3.5           1.4          0.2      setosa\n",
       "1             4.9          3.0           1.4          0.2      setosa\n",
       "2             4.7          3.2           1.3          0.2      setosa\n",
       "3             4.6          3.1           1.5          0.2      setosa\n",
       "4             5.0          3.6           1.4          0.2      setosa\n",
       "50            7.0          3.2           4.7          1.4  versicolor\n",
       "51            6.4          3.2           4.5          1.5  versicolor\n",
       "52            6.9          3.1           4.9          1.5  versicolor\n",
       "53            5.5          2.3           4.0          1.3  versicolor\n",
       "54            6.5          2.8           4.6          1.5  versicolor\n",
       "100           6.3          3.3           6.0          2.5   virginica\n",
       "101           5.8          2.7           5.1          1.9   virginica\n",
       "102           7.1          3.0           5.9          2.1   virginica\n",
       "103           6.3          2.9           5.6          1.8   virginica\n",
       "104           6.5          3.0           5.8          2.2   virginica"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun(x):\n",
    "    pd.DataFrame._get_numeric_data(x).apply(lambda x: x +10)\n",
    "\n",
    "iris = pd.read_csv(url)\n",
    "    \n",
    "gr_iris = iris.groupby('species', as_index=False)\n",
    "for key, group in gr_iris:\n",
    "    group.iloc[:,:-1].apply(lambda x: x+1)\n",
    "    #group = group.iloc[:,:-1].transform(lambda x: x + np.mean(x))\n",
    "    #(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "gr_iris.head()\n",
    "#iris._get_numeric_data().apply(lambda x: x +10)\n",
    "\n",
    "#iris.groupby('species').apply(lambda x: pd.DataFrame._get_numeric_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>7.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>8.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>7.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>7.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>8.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>7.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>7.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>8.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>8.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>8.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>7.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>7.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>8.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>7.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>7.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>7.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>7.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>7.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>7.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>7.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>7.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>7.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>6.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             6.1          4.5           2.4          1.2\n",
       "1             5.9          4.0           2.4          1.2\n",
       "2             5.7          4.2           2.3          1.2\n",
       "3             5.6          4.1           2.5          1.2\n",
       "4             6.0          4.6           2.4          1.2\n",
       "5             6.4          4.9           2.7          1.4\n",
       "6             5.6          4.4           2.4          1.3\n",
       "7             6.0          4.4           2.5          1.2\n",
       "8             5.4          3.9           2.4          1.2\n",
       "9             5.9          4.1           2.5          1.1\n",
       "10            6.4          4.7           2.5          1.2\n",
       "11            5.8          4.4           2.6          1.2\n",
       "12            5.8          4.0           2.4          1.1\n",
       "13            5.3          4.0           2.1          1.1\n",
       "14            6.8          5.0           2.2          1.2\n",
       "15            6.7          5.4           2.5          1.4\n",
       "16            6.4          4.9           2.3          1.4\n",
       "17            6.1          4.5           2.4          1.3\n",
       "18            6.7          4.8           2.7          1.3\n",
       "19            6.1          4.8           2.5          1.3\n",
       "20            6.4          4.4           2.7          1.2\n",
       "21            6.1          4.7           2.5          1.4\n",
       "22            5.6          4.6           2.0          1.2\n",
       "23            6.1          4.3           2.7          1.5\n",
       "24            5.8          4.4           2.9          1.2\n",
       "25            6.0          4.0           2.6          1.2\n",
       "26            6.0          4.4           2.6          1.4\n",
       "27            6.2          4.5           2.5          1.2\n",
       "28            6.2          4.4           2.4          1.2\n",
       "29            5.7          4.2           2.6          1.2\n",
       "..            ...          ...           ...          ...\n",
       "120           7.9          4.2           6.7          3.3\n",
       "121           6.6          3.8           5.9          3.0\n",
       "122           8.7          3.8           7.7          3.0\n",
       "123           7.3          3.7           5.9          2.8\n",
       "124           7.7          4.3           6.7          3.1\n",
       "125           8.2          4.2           7.0          2.8\n",
       "126           7.2          3.8           5.8          2.8\n",
       "127           7.1          4.0           5.9          2.8\n",
       "128           7.4          3.8           6.6          3.1\n",
       "129           8.2          4.0           6.8          2.6\n",
       "130           8.4          3.8           7.1          2.9\n",
       "131           8.9          4.8           7.4          3.0\n",
       "132           7.4          3.8           6.6          3.2\n",
       "133           7.3          3.8           6.1          2.5\n",
       "134           7.1          3.6           6.6          2.4\n",
       "135           8.7          4.0           7.1          3.3\n",
       "136           7.3          4.4           6.6          3.4\n",
       "137           7.4          4.1           6.5          2.8\n",
       "138           7.0          4.0           5.8          2.8\n",
       "139           7.9          4.1           6.4          3.1\n",
       "140           7.7          4.1           6.6          3.4\n",
       "141           7.9          4.1           6.1          3.3\n",
       "142           6.8          3.7           6.1          2.9\n",
       "143           7.8          4.2           6.9          3.3\n",
       "144           7.7          4.3           6.7          3.5\n",
       "145           7.7          4.0           6.2          3.3\n",
       "146           7.3          3.5           6.0          2.9\n",
       "147           7.5          4.0           6.2          3.0\n",
       "148           7.2          4.4           6.4          3.3\n",
       "149           6.9          4.0           6.1          2.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_iris = iris.groupby('species', as_index=False)\n",
    "gr_iris.transform(lambda s: s+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function apply in module pandas.core.frame:\n",
      "\n",
      "apply(self, func, axis=0, broadcast=None, raw=False, reduce=None, result_type=None, args=(), **kwds)\n",
      "    Apply a function along an axis of the DataFrame.\n",
      "    \n",
      "    Objects passed to the function are Series objects whose index is\n",
      "    either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
      "    (``axis=1``). By default (``result_type=None``), the final return type\n",
      "    is inferred from the return type of the applied function. Otherwise,\n",
      "    it depends on the `result_type` argument.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    func : function\n",
      "        Function to apply to each column or row.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Axis along which the function is applied:\n",
      "    \n",
      "        * 0 or 'index': apply function to each column.\n",
      "        * 1 or 'columns': apply function to each row.\n",
      "    broadcast : bool, optional\n",
      "        Only relevant for aggregation functions:\n",
      "    \n",
      "        * ``False`` or ``None`` : returns a Series whose length is the\n",
      "          length of the index or the number of columns (based on the\n",
      "          `axis` parameter)\n",
      "        * ``True`` : results will be broadcast to the original shape\n",
      "          of the frame, the original index and columns will be retained.\n",
      "    \n",
      "        .. deprecated:: 0.23.0\n",
      "           This argument will be removed in a future version, replaced\n",
      "           by result_type='broadcast'.\n",
      "    \n",
      "    raw : bool, default False\n",
      "        * ``False`` : passes each row or column as a Series to the\n",
      "          function.\n",
      "        * ``True`` : the passed function will receive ndarray objects\n",
      "          instead.\n",
      "          If you are just applying a NumPy reduction function this will\n",
      "          achieve much better performance.\n",
      "    reduce : bool or None, default None\n",
      "        Try to apply reduction procedures. If the DataFrame is empty,\n",
      "        `apply` will use `reduce` to determine whether the result\n",
      "        should be a Series or a DataFrame. If ``reduce=None`` (the\n",
      "        default), `apply`'s return value will be guessed by calling\n",
      "        `func` on an empty Series\n",
      "        (note: while guessing, exceptions raised by `func` will be\n",
      "        ignored).\n",
      "        If ``reduce=True`` a Series will always be returned, and if\n",
      "        ``reduce=False`` a DataFrame will always be returned.\n",
      "    \n",
      "        .. deprecated:: 0.23.0\n",
      "           This argument will be removed in a future version, replaced\n",
      "           by ``result_type='reduce'``.\n",
      "    \n",
      "    result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
      "        These only act when ``axis=1`` (columns):\n",
      "    \n",
      "        * 'expand' : list-like results will be turned into columns.\n",
      "        * 'reduce' : returns a Series if possible rather than expanding\n",
      "          list-like results. This is the opposite of 'expand'.\n",
      "        * 'broadcast' : results will be broadcast to the original shape\n",
      "          of the DataFrame, the original index and columns will be\n",
      "          retained.\n",
      "    \n",
      "        The default behaviour (None) depends on the return value of the\n",
      "        applied function: list-like results will be returned as a Series\n",
      "        of those. However if the apply function returns a Series these\n",
      "        are expanded to columns.\n",
      "    \n",
      "        .. versionadded:: 0.23.0\n",
      "    \n",
      "    args : tuple\n",
      "        Positional arguments to pass to `func` in addition to the\n",
      "        array/series.\n",
      "    **kwds\n",
      "        Additional keyword arguments to pass as keywords arguments to\n",
      "        `func`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    applied : Series or DataFrame\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.applymap: For elementwise operations.\n",
      "    DataFrame.aggregate: Only perform aggregating type operations.\n",
      "    DataFrame.transform: Only perform transforming type operations.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    In the current implementation apply calls `func` twice on the\n",
      "    first column/row to decide whether it can take a fast or slow\n",
      "    code path. This can lead to unexpected behavior if `func` has\n",
      "    side-effects, as they will take effect twice for the first\n",
      "    column/row.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    >>> df = pd.DataFrame([[4, 9],] * 3, columns=['A', 'B'])\n",
      "    >>> df\n",
      "       A  B\n",
      "    0  4  9\n",
      "    1  4  9\n",
      "    2  4  9\n",
      "    \n",
      "    Using a numpy universal function (in this case the same as\n",
      "    ``np.sqrt(df)``):\n",
      "    \n",
      "    >>> df.apply(np.sqrt)\n",
      "         A    B\n",
      "    0  2.0  3.0\n",
      "    1  2.0  3.0\n",
      "    2  2.0  3.0\n",
      "    \n",
      "    Using a reducing function on either axis\n",
      "    \n",
      "    >>> df.apply(np.sum, axis=0)\n",
      "    A    12\n",
      "    B    27\n",
      "    dtype: int64\n",
      "    \n",
      "    >>> df.apply(np.sum, axis=1)\n",
      "    0    13\n",
      "    1    13\n",
      "    2    13\n",
      "    dtype: int64\n",
      "    \n",
      "    Retuning a list-like will result in a Series\n",
      "    \n",
      "    >>> df.apply(lambda x: [1, 2], axis=1)\n",
      "    0    [1, 2]\n",
      "    1    [1, 2]\n",
      "    2    [1, 2]\n",
      "    dtype: object\n",
      "    \n",
      "    Passing result_type='expand' will expand list-like results\n",
      "    to columns of a Dataframe\n",
      "    \n",
      "    >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
      "       0  1\n",
      "    0  1  2\n",
      "    1  1  2\n",
      "    2  1  2\n",
      "    \n",
      "    Returning a Series inside the function is similar to passing\n",
      "    ``result_type='expand'``. The resulting column names\n",
      "    will be the Series index.\n",
      "    \n",
      "    >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
      "       foo  bar\n",
      "    0    1    2\n",
      "    1    1    2\n",
      "    2    1    2\n",
      "    \n",
      "    Passing ``result_type='broadcast'`` will ensure the same shape\n",
      "    result, whether list-like or scalar is returned by the function,\n",
      "    and broadcast it along the axis. The resulting column names will\n",
      "    be the originals.\n",
      "    \n",
      "    >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
      "       A  B\n",
      "    0  1  2\n",
      "    1  1  2\n",
      "    2  1  2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function transform in module pandas.core.frame:\n",
      "\n",
      "transform(self, func, axis=0, *args, **kwargs)\n",
      "    Call ``func`` on self producing a DataFrame with transformed values\n",
      "    and that has the same axis length as self.\n",
      "    \n",
      "    .. versionadded:: 0.20.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    func : function, str, list or dict\n",
      "        Function to use for transforming the data. If a function, must either\n",
      "        work when passed a DataFrame or when passed to DataFrame.apply.\n",
      "    \n",
      "        Accepted combinations are:\n",
      "    \n",
      "        - function\n",
      "        - string function name\n",
      "        - list of functions and/or function names, e.g. ``[np.exp. 'sqrt']``\n",
      "        - dict of axis labels -> functions, function names or list of such.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        If 0 or 'index': apply function to each column.\n",
      "        If 1 or 'columns': apply function to each row.\n",
      "    *args\n",
      "        Positional arguments to pass to `func`.\n",
      "    **kwargs\n",
      "        Keyword arguments to pass to `func`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        A DataFrame that must have the same length as self.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    ValueError : If the returned DataFrame has a different length than self.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.agg : Only perform aggregating type operations.\n",
      "    DataFrame.apply : Invoke function on a DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
      "    >>> df\n",
      "       A  B\n",
      "    0  0  1\n",
      "    1  1  2\n",
      "    2  2  3\n",
      "    >>> df.transform(lambda x: x + 1)\n",
      "       A  B\n",
      "    0  1  2\n",
      "    1  2  3\n",
      "    2  3  4\n",
      "    \n",
      "    Even though the resulting DataFrame must have the same length as the\n",
      "    input DataFrame, it is possible to provide several input functions:\n",
      "    \n",
      "    >>> s = pd.Series(range(3))\n",
      "    >>> s\n",
      "    0    0\n",
      "    1    1\n",
      "    2    2\n",
      "    dtype: int64\n",
      "    >>> s.transform([np.sqrt, np.exp])\n",
      "           sqrt        exp\n",
      "    0  0.000000   1.000000\n",
      "    1  1.000000   2.718282\n",
      "    2  1.414214   7.389056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length_std</th>\n",
       "      <th>sepal_width_std</th>\n",
       "      <th>petal_length_std</th>\n",
       "      <th>petal_width_std</th>\n",
       "      <th>sepal_length_mean</th>\n",
       "      <th>sepal_width_mean</th>\n",
       "      <th>petal_length_mean</th>\n",
       "      <th>petal_width_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>0.352490</td>\n",
       "      <td>0.379064</td>\n",
       "      <td>0.173664</td>\n",
       "      <td>0.105386</td>\n",
       "      <td>5.006</td>\n",
       "      <td>3.428</td>\n",
       "      <td>1.462</td>\n",
       "      <td>0.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>0.516171</td>\n",
       "      <td>0.313798</td>\n",
       "      <td>0.469911</td>\n",
       "      <td>0.197753</td>\n",
       "      <td>5.936</td>\n",
       "      <td>2.770</td>\n",
       "      <td>4.260</td>\n",
       "      <td>1.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>0.635880</td>\n",
       "      <td>0.322497</td>\n",
       "      <td>0.551895</td>\n",
       "      <td>0.274650</td>\n",
       "      <td>6.588</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.552</td>\n",
       "      <td>2.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sepal_length_std  sepal_width_std  petal_length_std  \\\n",
       "species                                                           \n",
       "setosa              0.352490         0.379064          0.173664   \n",
       "versicolor          0.516171         0.313798          0.469911   \n",
       "virginica           0.635880         0.322497          0.551895   \n",
       "\n",
       "            petal_width_std  sepal_length_mean  sepal_width_mean  \\\n",
       "species                                                            \n",
       "setosa             0.105386              5.006             3.428   \n",
       "versicolor         0.197753              5.936             2.770   \n",
       "virginica          0.274650              6.588             2.974   \n",
       "\n",
       "            petal_length_mean  petal_width_mean  \n",
       "species                                          \n",
       "setosa                  1.462             0.246  \n",
       "versicolor              4.260             1.326  \n",
       "virginica               5.552             2.026  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds = iris.groupby('species').std()\n",
    "means = iris.groupby('species').mean()\n",
    "pd.merge(stds,means, on='species', suffixes=['_std', '_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>0.352490</td>\n",
       "      <td>0.379064</td>\n",
       "      <td>0.173664</td>\n",
       "      <td>0.105386</td>\n",
       "      <td>5.006</td>\n",
       "      <td>3.428</td>\n",
       "      <td>1.462</td>\n",
       "      <td>0.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>0.516171</td>\n",
       "      <td>0.313798</td>\n",
       "      <td>0.469911</td>\n",
       "      <td>0.197753</td>\n",
       "      <td>5.936</td>\n",
       "      <td>2.770</td>\n",
       "      <td>4.260</td>\n",
       "      <td>1.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>0.635880</td>\n",
       "      <td>0.322497</td>\n",
       "      <td>0.551895</td>\n",
       "      <td>0.274650</td>\n",
       "      <td>6.588</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.552</td>\n",
       "      <td>2.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sepal_length  sepal_width  petal_length  petal_width  \\\n",
       "species                                                            \n",
       "setosa          0.352490     0.379064      0.173664     0.105386   \n",
       "versicolor      0.516171     0.313798      0.469911     0.197753   \n",
       "virginica       0.635880     0.322497      0.551895     0.274650   \n",
       "\n",
       "            sepal_length  sepal_width  petal_length  petal_width  \n",
       "species                                                           \n",
       "setosa             5.006        3.428         1.462        0.246  \n",
       "versicolor         5.936        2.770         4.260        1.326  \n",
       "virginica          6.588        2.974         5.552        2.026  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([stds, means], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length\n",
      "sepal_width\n",
      "petal_length\n",
      "petal_width\n",
      "species\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sepal_length    None\n",
       "sepal_width     None\n",
       "petal_length    None\n",
       "petal_width     None\n",
       "species         None\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.apply(lambda x: print(x.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266674</td>\n",
       "      <td>0.189941</td>\n",
       "      <td>-0.357011</td>\n",
       "      <td>-0.436492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.300718</td>\n",
       "      <td>-1.129096</td>\n",
       "      <td>-0.357011</td>\n",
       "      <td>-0.436492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.868111</td>\n",
       "      <td>-0.601481</td>\n",
       "      <td>-0.932836</td>\n",
       "      <td>-0.436492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.151807</td>\n",
       "      <td>-0.865288</td>\n",
       "      <td>0.218813</td>\n",
       "      <td>-0.436492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.017022</td>\n",
       "      <td>0.453749</td>\n",
       "      <td>-0.357011</td>\n",
       "      <td>-0.436492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0      0.266674     0.189941     -0.357011    -0.436492\n",
       "1     -0.300718    -1.129096     -0.357011    -0.436492\n",
       "2     -0.868111    -0.601481     -0.932836    -0.436492\n",
       "3     -1.151807    -0.865288      0.218813    -0.436492\n",
       "4     -0.017022     0.453749     -0.357011    -0.436492"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv(url)\n",
    "transformed = iris.groupby('species').transform(lambda x: (x - x.mean()) / x.std())\n",
    "transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>-0.875029</td>\n",
       "      <td>0.470443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>one</td>\n",
       "      <td>1.502322</td>\n",
       "      <td>-0.853530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>0.324685</td>\n",
       "      <td>-0.548743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bar</td>\n",
       "      <td>three</td>\n",
       "      <td>-0.952267</td>\n",
       "      <td>0.433413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>-0.318535</td>\n",
       "      <td>0.468800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A      B         C         D\n",
       "0  foo    one -0.875029  0.470443\n",
       "1  bar    one  1.502322 -0.853530\n",
       "2  foo    two  0.324685 -0.548743\n",
       "3  bar  three -0.952267  0.433413\n",
       "4  foo    two -0.318535  0.468800"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar',\n",
    "                          'foo', 'bar', 'foo', 'foo'],\n",
    "                    'B': ['one', 'one', 'two', 'three',\n",
    "                          'two', 'two', 'one', 'three'],\n",
    "                    'C': np.random.randn(8),\n",
    "                    'D': np.random.randn(8)})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.169512</td>\n",
       "      <td>0.060120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.099479</td>\n",
       "      <td>-1.154583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.738560</td>\n",
       "      <td>-0.903202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.855288</td>\n",
       "      <td>0.563029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.284442</td>\n",
       "      <td>0.058566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          C         D\n",
       "0 -1.169512  0.060120\n",
       "1  1.099479 -1.154583\n",
       "2  0.738560 -0.903202\n",
       "3 -0.855288  0.563029\n",
       "4 -0.284442  0.058566"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df = df.groupby('A').transform(lambda x: (x - x.mean()) / x.std())\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>7.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>8.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>7.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>7.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>8.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>7.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>7.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>8.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>8.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>8.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>7.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>7.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>8.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>7.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>7.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>7.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>7.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>7.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>7.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>7.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>7.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>7.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>6.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             6.1          4.5           2.4          1.2\n",
       "1             5.9          4.0           2.4          1.2\n",
       "2             5.7          4.2           2.3          1.2\n",
       "3             5.6          4.1           2.5          1.2\n",
       "4             6.0          4.6           2.4          1.2\n",
       "5             6.4          4.9           2.7          1.4\n",
       "6             5.6          4.4           2.4          1.3\n",
       "7             6.0          4.4           2.5          1.2\n",
       "8             5.4          3.9           2.4          1.2\n",
       "9             5.9          4.1           2.5          1.1\n",
       "10            6.4          4.7           2.5          1.2\n",
       "11            5.8          4.4           2.6          1.2\n",
       "12            5.8          4.0           2.4          1.1\n",
       "13            5.3          4.0           2.1          1.1\n",
       "14            6.8          5.0           2.2          1.2\n",
       "15            6.7          5.4           2.5          1.4\n",
       "16            6.4          4.9           2.3          1.4\n",
       "17            6.1          4.5           2.4          1.3\n",
       "18            6.7          4.8           2.7          1.3\n",
       "19            6.1          4.8           2.5          1.3\n",
       "20            6.4          4.4           2.7          1.2\n",
       "21            6.1          4.7           2.5          1.4\n",
       "22            5.6          4.6           2.0          1.2\n",
       "23            6.1          4.3           2.7          1.5\n",
       "24            5.8          4.4           2.9          1.2\n",
       "25            6.0          4.0           2.6          1.2\n",
       "26            6.0          4.4           2.6          1.4\n",
       "27            6.2          4.5           2.5          1.2\n",
       "28            6.2          4.4           2.4          1.2\n",
       "29            5.7          4.2           2.6          1.2\n",
       "..            ...          ...           ...          ...\n",
       "120           7.9          4.2           6.7          3.3\n",
       "121           6.6          3.8           5.9          3.0\n",
       "122           8.7          3.8           7.7          3.0\n",
       "123           7.3          3.7           5.9          2.8\n",
       "124           7.7          4.3           6.7          3.1\n",
       "125           8.2          4.2           7.0          2.8\n",
       "126           7.2          3.8           5.8          2.8\n",
       "127           7.1          4.0           5.9          2.8\n",
       "128           7.4          3.8           6.6          3.1\n",
       "129           8.2          4.0           6.8          2.6\n",
       "130           8.4          3.8           7.1          2.9\n",
       "131           8.9          4.8           7.4          3.0\n",
       "132           7.4          3.8           6.6          3.2\n",
       "133           7.3          3.8           6.1          2.5\n",
       "134           7.1          3.6           6.6          2.4\n",
       "135           8.7          4.0           7.1          3.3\n",
       "136           7.3          4.4           6.6          3.4\n",
       "137           7.4          4.1           6.5          2.8\n",
       "138           7.0          4.0           5.8          2.8\n",
       "139           7.9          4.1           6.4          3.1\n",
       "140           7.7          4.1           6.6          3.4\n",
       "141           7.9          4.1           6.1          3.3\n",
       "142           6.8          3.7           6.1          2.9\n",
       "143           7.8          4.2           6.9          3.3\n",
       "144           7.7          4.3           6.7          3.5\n",
       "145           7.7          4.0           6.2          3.3\n",
       "146           7.3          3.5           6.0          2.9\n",
       "147           7.5          4.0           6.2          3.0\n",
       "148           7.2          4.4           6.4          3.3\n",
       "149           6.9          4.0           6.1          2.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.iloc[:,:-1].transform(lambda x: x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataFrameGroupBy in module pandas.core.groupby.generic:\n",
      "\n",
      "class DataFrameGroupBy(NDFrameGroupBy)\n",
      " |  DataFrameGroupBy(obj, keys=None, axis=0, level=None, grouper=None, exclusions=None, selection=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)\n",
      " |  \n",
      " |  Class for grouping and aggregating relational data.\n",
      " |  \n",
      " |  See aggregate, transform, and apply functions on this object.\n",
      " |  \n",
      " |  It's easiest to use obj.groupby(...) to use GroupBy, but you can also do:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      grouped = groupby(obj, ...)\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  obj : pandas object\n",
      " |  axis : int, default 0\n",
      " |  level : int, default None\n",
      " |      Level of MultiIndex\n",
      " |  groupings : list of Grouping objects\n",
      " |      Most users should ignore this\n",
      " |  exclusions : array-like, optional\n",
      " |      List of columns to exclude\n",
      " |  name : string\n",
      " |      Most users should ignore this\n",
      " |  \n",
      " |  Returns\n",
      " |  -------\n",
      " |  **Attributes**\n",
      " |  groups : dict\n",
      " |      {group name -> group labels}\n",
      " |  len(grouped) : int\n",
      " |      Number of groups\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  After grouping, see aggregate, apply, and transform functions. Here are\n",
      " |  some other brief notes about usage. When grouping by multiple groups, the\n",
      " |  result index will be a MultiIndex (hierarchical) by default.\n",
      " |  \n",
      " |  Iteration produces (key, group) tuples, i.e. chunking the data by group. So\n",
      " |  you can write code like:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      grouped = obj.groupby(keys, axis=axis)\n",
      " |      for key, group in grouped:\n",
      " |          # do something with the data\n",
      " |  \n",
      " |  Function calls on GroupBy, if not specially implemented, \"dispatch\" to the\n",
      " |  grouped data. So if you group a DataFrame and wish to invoke the std()\n",
      " |  method on each group, you can simply do:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      df.groupby(mapper).std()\n",
      " |  \n",
      " |  rather than\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      df.groupby(mapper).aggregate(np.std)\n",
      " |  \n",
      " |  You can pass arguments to these \"wrapped\" functions, too.\n",
      " |  \n",
      " |  See the online documentation for full exposition on these topics and much\n",
      " |  more\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrameGroupBy\n",
      " |      NDFrameGroupBy\n",
      " |      pandas.core.groupby.groupby.GroupBy\n",
      " |      pandas.core.groupby.groupby._GroupBy\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  agg = aggregate(self, arg, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, arg, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      \n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame, Series or scalar\n",
      " |          if DataFrame.agg is called with a single function, returns a Series\n",
      " |          if DataFrame.agg is called with several functions, returns a DataFrame\n",
      " |          if Series.agg is called with single function, returns a scalar\n",
      " |          if Series.agg is called with several functions, returns a Series\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.groupby.apply\n",
      " |      pandas.DataFrame.groupby.transform\n",
      " |      pandas.DataFrame.aggregate\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 2],\n",
      " |      ...                    'B': [1, 2, 3, 4],\n",
      " |      ...                    'C': np.random.randn(4)})\n",
      " |      \n",
      " |      >>> df\n",
      " |         A  B         C\n",
      " |      0  1  1  0.362838\n",
      " |      1  1  2  0.227877\n",
      " |      2  2  3  1.267767\n",
      " |      3  2  4 -0.562860\n",
      " |      \n",
      " |      The aggregation is for each column.\n",
      " |      \n",
      " |      >>> df.groupby('A').agg('min')\n",
      " |         B         C\n",
      " |      A\n",
      " |      1  1  0.227877\n",
      " |      2  3 -0.562860\n",
      " |      \n",
      " |      Multiple aggregations\n",
      " |      \n",
      " |      >>> df.groupby('A').agg(['min', 'max'])\n",
      " |          B             C\n",
      " |        min max       min       max\n",
      " |      A\n",
      " |      1   1   2  0.227877  0.362838\n",
      " |      2   3   4 -0.562860  1.267767\n",
      " |      \n",
      " |      Select a column for aggregation\n",
      " |      \n",
      " |      >>> df.groupby('A').B.agg(['min', 'max'])\n",
      " |         min  max\n",
      " |      A\n",
      " |      1    1    2\n",
      " |      2    3    4\n",
      " |      \n",
      " |      Different aggregations per column\n",
      " |      \n",
      " |      >>> df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})\n",
      " |          B             C\n",
      " |        min max       sum\n",
      " |      A\n",
      " |      1   1   2  0.590716\n",
      " |      2   3   4  0.704907\n",
      " |  \n",
      " |  boxplot = boxplot_frame_groupby(grouped, subplots=True, column=None, fontsize=None, rot=0, grid=True, ax=None, figsize=None, layout=None, sharex=False, sharey=True, **kwds)\n",
      " |      Make box plots from DataFrameGroupBy data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      grouped : Grouped DataFrame\n",
      " |      subplots :\n",
      " |          * ``False`` - no subplots will be used\n",
      " |          * ``True`` - create a subplot for each group\n",
      " |      column : column name or list of names, or vector\n",
      " |          Can be any valid input to groupby\n",
      " |      fontsize : int or string\n",
      " |      rot : label rotation angle\n",
      " |      grid : Setting this to True will show the grid\n",
      " |      ax : Matplotlib axis object, default None\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |      layout : tuple (optional)\n",
      " |          (rows, columns) for the layout of the plot\n",
      " |      sharex : bool, default False\n",
      " |          Whether x-axes will be shared among subplots\n",
      " |      \n",
      " |          .. versionadded:: 0.23.1\n",
      " |      sharey : bool, default True\n",
      " |          Whether y-axes will be shared among subplots\n",
      " |      \n",
      " |          .. versionadded:: 0.23.1\n",
      " |      `**kwds` : Keyword Arguments\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          matplotlib's boxplot function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict of key/value = group key/DataFrame.boxplot return value\n",
      " |      or DataFrame.boxplot return value in case subplots=figures=False\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import itertools\n",
      " |      >>> tuples = [t for t in itertools.product(range(1000), range(4))]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples, names=['lvl0', 'lvl1'])\n",
      " |      >>> data = np.random.randn(len(index),4)\n",
      " |      >>> df = pd.DataFrame(data, columns=list('ABCD'), index=index)\n",
      " |      >>>\n",
      " |      >>> grouped = df.groupby(level='lvl1')\n",
      " |      >>> boxplot_frame_groupby(grouped)\n",
      " |      >>>\n",
      " |      >>> grouped = df.unstack(level='lvl1').groupby(level=0, axis=1)\n",
      " |      >>> boxplot_frame_groupby(grouped, subplots=False)\n",
      " |  \n",
      " |  count(self)\n",
      " |      Compute count of group, excluding missing values\n",
      " |  \n",
      " |  nunique(self, dropna=True)\n",
      " |      Return DataFrame with number of distinct observations per group for\n",
      " |      each column.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique: DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'id': ['spam', 'egg', 'egg', 'spam',\n",
      " |      ...                           'ham', 'ham'],\n",
      " |      ...                    'value1': [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'value2': list('abbaxy')})\n",
      " |      >>> df\n",
      " |           id  value1 value2\n",
      " |      0  spam       1      a\n",
      " |      1   egg       5      b\n",
      " |      2   egg       5      b\n",
      " |      3  spam       2      a\n",
      " |      4   ham       5      x\n",
      " |      5   ham       5      y\n",
      " |      \n",
      " |      >>> df.groupby('id').nunique()\n",
      " |          id  value1  value2\n",
      " |      id\n",
      " |      egg    1       1       1\n",
      " |      ham    1       1       2\n",
      " |      spam   1       2       1\n",
      " |      \n",
      " |      # check for rows with the same id but conflicting values\n",
      " |      >>> df.groupby('id').filter(lambda g: (g.nunique() > 1).any())\n",
      " |           id  value1 value2\n",
      " |      0  spam       1      a\n",
      " |      3  spam       2      a\n",
      " |      4   ham       5      x\n",
      " |      5   ham       5      y\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  corr\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float\n",
      " |              .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for pearson\n",
      " |          and spearman correlation\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corrwith\n",
      " |      Series.corr\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> histogram_intersection = lambda a, b: np.minimum(a, b\n",
      " |      ... ).sum().round(decimals=1)\n",
      " |      >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(method=histogram_intersection)\n",
      " |            dogs cats\n",
      " |      dogs   1.0  0.3\n",
      " |      cats   0.3  1.0\n",
      " |  \n",
      " |  corrwith\n",
      " |      Compute pairwise correlation between rows or columns of DataFrame\n",
      " |      with rows or columns of Series or DataFrame.  DataFrames are first\n",
      " |      aligned along both axes before computing the correlations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' to compute column-wise, 1 or 'columns' for row-wise\n",
      " |      drop : boolean, default False\n",
      " |          Drop missing indices from result\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correls : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      -------\n",
      " |      DataFrame.corr\n",
      " |  \n",
      " |  cov\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Compute the pairwise covariance among the series of a DataFrame.\n",
      " |      The returned data frame is the `covariance matrix\n",
      " |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      " |      of the DataFrame.\n",
      " |      \n",
      " |      Both NA and null values are automatically excluded from the\n",
      " |      calculation. (See the note below about bias from missing values.)\n",
      " |      A threshold can be set for the minimum number of\n",
      " |      observations for each value created. Comparisons with observations\n",
      " |      below this threshold will be returned as ``NaN``.\n",
      " |      \n",
      " |      This method is generally used for the analysis of time series data to\n",
      " |      understand the relationship between different measures\n",
      " |      across time.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The covariance matrix of the series of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.cov : Compute covariance with another Series.\n",
      " |      pandas.core.window.EWM.cov: Exponential weighted sample covariance.\n",
      " |      pandas.core.window.Expanding.cov : Expanding sample covariance.\n",
      " |      pandas.core.window.Rolling.cov : Rolling sample covariance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-1.\n",
      " |      \n",
      " |      For DataFrames that have Series that are missing data (assuming that\n",
      " |      data is `missing at random\n",
      " |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      " |      the returned covariance matrix will be an unbiased estimate\n",
      " |      of the variance and covariance between the member Series.\n",
      " |      \n",
      " |      However, for many applications this estimate may not be acceptable\n",
      " |      because the estimate covariance matrix is not guaranteed to be positive\n",
      " |      semi-definite. This could lead to estimate correlations having\n",
      " |      absolute values which are greater than one, and/or a non-invertible\n",
      " |      covariance matrix. See `Estimation of covariance matrices\n",
      " |      <http://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      " |      matrices>`__ for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.cov()\n",
      " |                dogs      cats\n",
      " |      dogs  0.666667 -1.000000\n",
      " |      cats -1.000000  1.666667\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      " |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> df.cov()\n",
      " |                a         b         c         d         e\n",
      " |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      " |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      " |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      " |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      " |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      " |      \n",
      " |      **Minimum number of periods**\n",
      " |      \n",
      " |      This method also supports an optional ``min_periods`` keyword\n",
      " |      that specifies the required minimum number of non-NA observations for\n",
      " |      each column pair in order to have a valid result:\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      " |      ...                   columns=['a', 'b', 'c'])\n",
      " |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      " |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      " |      >>> df.cov(min_periods=12)\n",
      " |                a         b         c\n",
      " |      a  0.316741       NaN -0.150812\n",
      " |      b       NaN  1.248003  0.191417\n",
      " |      c -0.150812  0.191417  0.895202\n",
      " |  \n",
      " |  diff\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a DataFrame element compared with another\n",
      " |      element in the DataFrame (default is the element in the same column\n",
      " |      of the previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |          .. versionadded:: 0.16.1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff: First discrete difference for a Series.\n",
      " |      DataFrame.pct_change: Percent change over given number of periods.\n",
      " |      DataFrame.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'b': [1, 1, 2, 3, 5, 8],\n",
      " |      ...                    'c': [1, 4, 9, 16, 25, 36]})\n",
      " |      >>> df\n",
      " |         a  b   c\n",
      " |      0  1  1   1\n",
      " |      1  2  1   4\n",
      " |      2  3  2   9\n",
      " |      3  4  3  16\n",
      " |      4  5  5  25\n",
      " |      5  6  8  36\n",
      " |      \n",
      " |      >>> df.diff()\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  1.0  0.0   3.0\n",
      " |      2  1.0  1.0   5.0\n",
      " |      3  1.0  1.0   7.0\n",
      " |      4  1.0  2.0   9.0\n",
      " |      5  1.0  3.0  11.0\n",
      " |      \n",
      " |      Difference with previous column\n",
      " |      \n",
      " |      >>> df.diff(axis=1)\n",
      " |          a    b     c\n",
      " |      0 NaN  0.0   0.0\n",
      " |      1 NaN -1.0   3.0\n",
      " |      2 NaN -1.0   7.0\n",
      " |      3 NaN -1.0  13.0\n",
      " |      4 NaN  0.0  20.0\n",
      " |      5 NaN  2.0  28.0\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> df.diff(periods=3)\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  NaN   NaN\n",
      " |      2  NaN  NaN   NaN\n",
      " |      3  3.0  2.0  15.0\n",
      " |      4  3.0  4.0  21.0\n",
      " |      5  3.0  6.0  27.0\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> df.diff(periods=-1)\n",
      " |           a    b     c\n",
      " |      0 -1.0  0.0  -3.0\n",
      " |      1 -1.0 -1.0  -5.0\n",
      " |      2 -1.0 -1.0  -7.0\n",
      " |      3 -1.0 -2.0  -9.0\n",
      " |      4 -1.0 -3.0 -11.0\n",
      " |      5  NaN  NaN   NaN\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in the DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype. See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type of each column.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.ftypes : Dtype and sparsity information.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'float': [1.0],\n",
      " |      ...                    'int': [1],\n",
      " |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      " |      ...                    'string': ['foo']})\n",
      " |      >>> df.dtypes\n",
      " |      float              float64\n",
      " |      int                  int64\n",
      " |      datetime    datetime64[ns]\n",
      " |      string              object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  fillna\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame). (values not\n",
      " |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                    columns=list('ABCD'))\n",
      " |      >>> df\n",
      " |           A    B   C  D\n",
      " |      0  NaN  2.0 NaN  0\n",
      " |      1  3.0  4.0 NaN  1\n",
      " |      2  NaN  NaN NaN  5\n",
      " |      3  NaN  3.0 NaN  4\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method='ffill')\n",
      " |          A   B   C   D\n",
      " |      0   NaN 2.0 NaN 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   3.0 4.0 NaN 5\n",
      " |      3   3.0 3.0 NaN 4\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 2.0 1\n",
      " |      2   0.0 1.0 2.0 5\n",
      " |      3   0.0 3.0 2.0 4\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   NaN 1.0 NaN 5\n",
      " |      3   NaN 3.0 NaN 4\n",
      " |  \n",
      " |  hist\n",
      " |      Make a histogram of the DataFrame's.\n",
      " |      \n",
      " |      A `histogram`_ is a representation of the distribution of data.\n",
      " |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      " |      the DataFrame, resulting in one histogram per column.\n",
      " |      \n",
      " |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          The pandas object holding the data.\n",
      " |      column : string or sequence\n",
      " |          If passed, will be used to limit data to a subset of columns.\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      " |          x labels rotated 90 degrees clockwise.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      " |          y labels rotated 90 degrees clockwise.\n",
      " |      ax : Matplotlib axes object, default None\n",
      " |          The axes to plot the histogram on.\n",
      " |      sharex : boolean, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in.\n",
      " |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      " |          labels for all subplots in a figure.\n",
      " |      sharey : boolean, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible.\n",
      " |      figsize : tuple\n",
      " |          The size in inches of the figure to create. Uses the value in\n",
      " |          `matplotlib.rcParams` by default.\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms.\n",
      " |      bins : integer or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      **kwds\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :meth:`matplotlib.pyplot.hist`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      axes : matplotlib.AxesSubplot or numpy.ndarray of them\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          This example draws a histogram based on the length and width of\n",
      " |          some animals, displayed in three bins\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\n",
      " |          ...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
      " |          ...     }, index= ['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> hist = df.hist(bins=3)\n",
      " |  \n",
      " |  idxmax\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Series\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |  \n",
      " |  idxmin\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Series\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |  \n",
      " |  mad\n",
      " |      Return the mean absolute deviation of the values for the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  quantile\n",
      " |      Return values at the given quantile over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          Value between 0 <= q <= 1, the quantile(s) to compute.\n",
      " |      axis : {0, 1, 'index', 'columns'} (default 0)\n",
      " |          Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      numeric_only : bool, default True\n",
      " |          If False, the quantile of datetime and timedelta data will be\n",
      " |          computed as well.\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantiles : Series or DataFrame\n",
      " |      \n",
      " |          - If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          - If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Rolling.quantile: Rolling quantile.\n",
      " |      numpy.percentile: Numpy function to compute the percentile.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      Name: 0.1, dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |      \n",
      " |      Specifying `numeric_only=False` will also compute the quantile of\n",
      " |      datetime and timedelta data.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2],\n",
      " |      ...                    'B': [pd.Timestamp('2010'),\n",
      " |      ...                          pd.Timestamp('2011')],\n",
      " |      ...                    'C': [pd.Timedelta('1 days'),\n",
      " |      ...                          pd.Timedelta('2 days')]})\n",
      " |      >>> df.quantile(0.5, numeric_only=False)\n",
      " |      A                    1.5\n",
      " |      B    2010-07-02 12:00:00\n",
      " |      C        1 days 12:00:00\n",
      " |      Name: 0.5, dtype: object\n",
      " |  \n",
      " |  skew\n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  take\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      convert : bool, default True\n",
      " |          Whether to convert negative indices into positive ones.\n",
      " |          For example, ``-1`` would map to the ``len(axis) - 1``.\n",
      " |          The conversions are similar to the behavior of indexing a\n",
      " |          regular Python list.\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |             In the future, negative indices will always be converted.\n",
      " |      \n",
      " |      is_copy : bool, default True\n",
      " |          Whether to return a copy of the original object or not.\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : same type as caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                    columns=['name', 'class', 'max_speed'],\n",
      " |      ...                    index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  tshift\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from NDFrameGroupBy:\n",
      " |  \n",
      " |  filter(self, func, dropna=True, *args, **kwargs)\n",
      " |      Return a copy of a DataFrame excluding elements from groups that\n",
      " |      do not satisfy the boolean criterion specified by func.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function\n",
      " |          Function to apply to each subframe. Should return True or False.\n",
      " |      dropna : Drop groups that do not pass the filter. True by default;\n",
      " |          if False, groups that evaluate False are filled with NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filtered : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each subframe is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'C' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> grouped.filter(lambda x: x['B'].mean() > 3.)\n",
      " |           A  B    C\n",
      " |      1  bar  2  5.0\n",
      " |      3  bar  4  1.0\n",
      " |      5  bar  6  9.0\n",
      " |  \n",
      " |  transform(self, func, *args, **kwargs)\n",
      " |      Call function producing a like-indexed DataFrame on each group and\n",
      " |      return a DataFrame having the same indexes as the original object\n",
      " |      filled with the transformed values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function\n",
      " |          Function to apply to each group\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      aggregate, transform\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each group is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      The current implementation imposes three requirements on f:\n",
      " |      \n",
      " |      * f must return a value that either has the same shape as the input\n",
      " |        subframe or can be broadcast to the shape of the input subframe.\n",
      " |        For example, f returns a scalar it will be broadcast to have the\n",
      " |        same shape as the input subframe.\n",
      " |      * if this is a DataFrame, f must support application column-by-column\n",
      " |        in the subframe. If f also supports application to the entire subframe,\n",
      " |        then a fast path is used starting from the second chunk.\n",
      " |      * f must not mutate groups. Mutation is not supported and may\n",
      " |        produce unexpected results.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      # Same shape\n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : ['one', 'one', 'two', 'three',\n",
      " |      ...                          'two', 'two'],\n",
      " |      ...                    'C' : [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'D' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |                C         D\n",
      " |      0 -1.154701 -0.577350\n",
      " |      1  0.577350  0.000000\n",
      " |      2  0.577350  1.154701\n",
      " |      3 -1.154701 -1.000000\n",
      " |      4  0.577350 -0.577350\n",
      " |      5  0.577350  1.000000\n",
      " |      \n",
      " |      # Broadcastable\n",
      " |      >>> grouped.transform(lambda x: x.max() - x.min())\n",
      " |         C    D\n",
      " |      0  4  6.0\n",
      " |      1  3  8.0\n",
      " |      2  4  6.0\n",
      " |      3  3  8.0\n",
      " |      4  4  6.0\n",
      " |      5  3  8.0\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.groupby.groupby.GroupBy:\n",
      " |  \n",
      " |  all(self, skipna=True)\n",
      " |      Returns True if all values in the group are truthful, else False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  any(self, skipna=True)\n",
      " |      Returns True if any value in the group is truthful, else False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  backfill(self, limit=None)\n",
      " |      Backward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.backfill\n",
      " |      DataFrame.backfill\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |  \n",
      " |  bfill = backfill(self, limit=None)\n",
      " |  \n",
      " |  cumcount(self, ascending=True)\n",
      " |      Number each item in each group from 0 to the length of that group - 1.\n",
      " |      \n",
      " |      Essentially this is equivalent to\n",
      " |      \n",
      " |      >>> self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from length of group - 1 to 0.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      .ngroup : Number the groups themselves.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').cumcount()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    0\n",
      " |      4    1\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').cumcount(ascending=False)\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    1\n",
      " |      3    1\n",
      " |      4    0\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  cummax(self, axis=0, **kwargs)\n",
      " |      Cumulative max for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cummin(self, axis=0, **kwargs)\n",
      " |      Cumulative min for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumprod(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative product for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumsum(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative sum for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  describe(self, **kwargs)\n",
      " |      Generate descriptive statistics that summarize the central tendency,\n",
      " |      dispersion and shape of a dataset's distribution, excluding\n",
      " |      ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the obersvations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                       3\n",
      " |      unique                      2\n",
      " |      top       2010-01-01 00:00:00\n",
      " |      freq                        2\n",
      " |      first     2000-01-01 00:00:00\n",
      " |      last      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')\n",
      " |              categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      c\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.object])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         c\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              f\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      c\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.object])\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |  \n",
      " |  expanding(self, *args, **kwargs)\n",
      " |      Return an expanding grouper, providing expanding\n",
      " |      functionality per group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ffill = pad(self, limit=None)\n",
      " |  \n",
      " |  first(self, **kwargs)\n",
      " |      Compute first of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Returns first n rows of each group.\n",
      " |      \n",
      " |      Essentially equivalent to ``.apply(lambda x: x.head(n))``,\n",
      " |      except ignores as_index flag.\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.%(name)s\n",
      " |      pandas.DataFrame.%(name)s\n",
      " |      pandas.Panel.%(name)s\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n",
      " |                            columns=['A', 'B'])\n",
      " |      >>> df.groupby('A', as_index=False).head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |  \n",
      " |  last(self, **kwargs)\n",
      " |      Compute last of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  max(self, **kwargs)\n",
      " |      Compute max of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  mean(self, *args, **kwargs)\n",
      " |      Compute mean of groups, excluding missing values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series or pandas.DataFrame\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.%(name)s\n",
      " |      pandas.DataFrame.%(name)s\n",
      " |      pandas.Panel.%(name)s\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5],\n",
      " |      ...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Groupby one column and return the mean of the remaining columns in\n",
      " |      each group.\n",
      " |      \n",
      " |      >>> df.groupby('A').mean()\n",
      " |      >>>\n",
      " |           B         C\n",
      " |      A\n",
      " |      1  3.0  1.333333\n",
      " |      2  4.0  1.500000\n",
      " |      \n",
      " |      Groupby two columns and return the mean of the remaining column.\n",
      " |      \n",
      " |      >>> df.groupby(['A', 'B']).mean()\n",
      " |      >>>\n",
      " |             C\n",
      " |      A B\n",
      " |      1 2.0  2\n",
      " |        4.0  1\n",
      " |      2 3.0  1\n",
      " |        5.0  2\n",
      " |      \n",
      " |      Groupby one column and return the mean of only particular column in\n",
      " |      the group.\n",
      " |      \n",
      " |      >>> df.groupby('A')['B'].mean()\n",
      " |      >>>\n",
      " |      A\n",
      " |      1    3.0\n",
      " |      2    4.0\n",
      " |      Name: B, dtype: float64\n",
      " |  \n",
      " |  median(self, **kwargs)\n",
      " |      Compute median of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  min(self, **kwargs)\n",
      " |      Compute min of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ngroup(self, ascending=True)\n",
      " |      Number each group from 0 to the number of groups - 1.\n",
      " |      \n",
      " |      This is the enumerative complement of cumcount.  Note that the\n",
      " |      numbers given to the groups match the order in which the groups\n",
      " |      would be seen when iterating over the groupby object, not the\n",
      " |      order they are first observed.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.2\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from number of group - 1 to 0.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      .cumcount : Number the rows in each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": list(\"aaabba\")})\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').ngroup()\n",
      " |      0    0\n",
      " |      1    0\n",
      " |      2    0\n",
      " |      3    1\n",
      " |      4    1\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').ngroup(ascending=False)\n",
      " |      0    1\n",
      " |      1    1\n",
      " |      2    1\n",
      " |      3    0\n",
      " |      4    0\n",
      " |      5    1\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby([\"A\", [1,1,2,3,2,1]]).ngroup()\n",
      " |      0    0\n",
      " |      1    0\n",
      " |      2    1\n",
      " |      3    3\n",
      " |      4    2\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  nth(self, n, dropna=None)\n",
      " |      Take the nth row from each group if n is an int, or a subset of rows\n",
      " |      if n is a list of ints.\n",
      " |      \n",
      " |      If dropna, will take the nth non-null row, dropna is either\n",
      " |      Truthy (if a Series) or 'all', 'any' (if a DataFrame);\n",
      " |      this is equivalent to calling dropna(how=dropna) before the\n",
      " |      groupby.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int or list of ints\n",
      " |          a single nth value for the row or a list of nth values\n",
      " |      dropna : None or str, optional\n",
      " |          apply the specified dropna operation before counting which row is\n",
      " |          the nth row. Needs to be None, 'any' or 'all'\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.%(name)s\n",
      " |      pandas.DataFrame.%(name)s\n",
      " |      pandas.Panel.%(name)s\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n",
      " |      >>> g = df.groupby('A')\n",
      " |      >>> g.nth(0)\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      2  3.0\n",
      " |      >>> g.nth(1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth(-1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  4.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth([0, 1])\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      2  5.0\n",
      " |      \n",
      " |      Specifying `dropna` allows count ignoring ``NaN``\n",
      " |      \n",
      " |      >>> g.nth(0, dropna='any')\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      \n",
      " |      NaNs denote group exhausted when using dropna\n",
      " |      \n",
      " |      >>> g.nth(3, dropna='any')\n",
      " |          B\n",
      " |      A\n",
      " |      1 NaN\n",
      " |      2 NaN\n",
      " |      \n",
      " |      Specifying `as_index=False` in `groupby` keeps the original index.\n",
      " |      \n",
      " |      >>> df.groupby('A', as_index=False).nth(1)\n",
      " |         A    B\n",
      " |      1  1  2.0\n",
      " |      4  2  5.0\n",
      " |  \n",
      " |  ohlc(self)\n",
      " |      Compute sum of values, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  pad(self, limit=None)\n",
      " |      Forward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pad\n",
      " |      DataFrame.pad\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, axis=0)\n",
      " |      Calculate pct_change of each value to previous entry in group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  prod(self, **kwargs)\n",
      " |      Compute prod of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  rank(self, method='average', ascending=True, na_option='keep', pct=False, axis=0)\n",
      " |      Provides the rank of values within each group.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      na_option :  {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      pct : boolean, default False\n",
      " |          Compute percentage rank of data within each group\n",
      " |      axis : int, default 0\n",
      " |          The axis of the object over which to compute the rank.\n",
      " |      \n",
      " |      Returns\n",
      " |      -----\n",
      " |      DataFrame with ranking of values within each group\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  resample(self, rule, *args, **kwargs)\n",
      " |      Provide resampling when using a TimeGrouper.\n",
      " |      \n",
      " |      Given a grouper, the function resamples it according to a string\n",
      " |      \"string\" -> \"frequency\".\n",
      " |      \n",
      " |      See the :ref:`frequency aliases <timeseries.offset_aliases>`\n",
      " |      documentation for more details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : str or DateOffset\n",
      " |          The offset string or object representing target grouper conversion.\n",
      " |      *args, **kwargs\n",
      " |          Possible arguments are `how`, `fill_method`, `limit`, `kind` and\n",
      " |          `on`, and other arguments of `TimeGrouper`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Grouper\n",
      " |          Return a new grouper with our resampler appended.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Grouper : Specify a frequency to resample with when\n",
      " |          grouping by a key.\n",
      " |      DatetimeIndex.resample : Frequency conversion and resampling of\n",
      " |          time series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> df = pd.DataFrame(data=4 * [range(2)],\n",
      " |      ...                   index=idx,\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.iloc[2, 0] = 5\n",
      " |      >>> df\n",
      " |                          a  b\n",
      " |      2000-01-01 00:00:00  0  1\n",
      " |      2000-01-01 00:01:00  0  1\n",
      " |      2000-01-01 00:02:00  5  1\n",
      " |      2000-01-01 00:03:00  0  1\n",
      " |      \n",
      " |      Downsample the DataFrame into 3 minute bins and sum the values of\n",
      " |      the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  2\n",
      " |          2000-01-01 00:03:00  0  1\n",
      " |      5   2000-01-01 00:00:00  5  1\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('30S').sum()\n",
      " |                          a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  1\n",
      " |          2000-01-01 00:00:30  0  0\n",
      " |          2000-01-01 00:01:00  0  1\n",
      " |          2000-01-01 00:01:30  0  0\n",
      " |          2000-01-01 00:02:00  0  0\n",
      " |          2000-01-01 00:02:30  0  0\n",
      " |          2000-01-01 00:03:00  0  1\n",
      " |      5   2000-01-01 00:02:00  5  1\n",
      " |      \n",
      " |      Resample by month. Values are assigned to the month of the period.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('M').sum()\n",
      " |                  a  b\n",
      " |      a\n",
      " |      0   2000-01-31  0  3\n",
      " |      5   2000-01-31  5  1\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', closed='right').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   1999-12-31 23:57:00  0  1\n",
      " |          2000-01-01 00:00:00  0  2\n",
      " |      5   2000-01-01 00:00:00  5  1\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and close the right side of\n",
      " |      the bin interval, but label each bin using the right edge instead of\n",
      " |      the left.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', closed='right', label='right').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  1\n",
      " |          2000-01-01 00:03:00  0  2\n",
      " |      5   2000-01-01 00:03:00  5  1\n",
      " |      \n",
      " |      Add an offset of twenty seconds.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', loffset='20s').sum()\n",
      " |                             a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:20  0  2\n",
      " |          2000-01-01 00:03:20  0  1\n",
      " |      5   2000-01-01 00:00:20  5  1\n",
      " |  \n",
      " |  rolling(self, *args, **kwargs)\n",
      " |      Return a rolling grouper, providing rolling functionality per group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  sem(self, ddof=1)\n",
      " |      Compute standard error of the mean of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0, fill_value=None)\n",
      " |      Shift each group by periods observations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : integer, default 1\n",
      " |          number of periods to shift\n",
      " |      freq : frequency string\n",
      " |      axis : axis to shift, default 0\n",
      " |      fill_value : optional\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  size(self)\n",
      " |      Compute group sizes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  std(self, ddof=1, *args, **kwargs)\n",
      " |      Compute standard deviation of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  sum(self, **kwargs)\n",
      " |      Compute sum of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Returns last n rows of each group.\n",
      " |      \n",
      " |      Essentially equivalent to ``.apply(lambda x: x.tail(n))``,\n",
      " |      except ignores as_index flag.\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.%(name)s\n",
      " |      pandas.DataFrame.%(name)s\n",
      " |      pandas.Panel.%(name)s\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n",
      " |                            columns=['A', 'B'])\n",
      " |      >>> df.groupby('A').tail(1)\n",
      " |         A  B\n",
      " |      1  a  2\n",
      " |      3  b  2\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  a  1\n",
      " |      2  b  1\n",
      " |  \n",
      " |  var(self, ddof=1, *args, **kwargs)\n",
      " |      Compute variance of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.groupby.groupby._GroupBy:\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |  \n",
      " |  __init__(self, obj, keys=None, axis=0, level=None, grouper=None, exclusions=None, selection=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Groupby iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Generator yielding sequence of (name, subsetted object)\n",
      " |      for each group\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by unicode(obj) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  apply(self, func, *args, **kwargs)\n",
      " |      Apply function `func`  group-wise and combine the results together.\n",
      " |      \n",
      " |      The function passed to `apply` must take a dataframe as its first\n",
      " |      argument and return a DataFrame, Series or scalar. `apply` will\n",
      " |      then take care of combining the results back together into a single\n",
      " |      dataframe or series. `apply` is therefore a highly flexible\n",
      " |      grouping method.\n",
      " |      \n",
      " |      While `apply` is a very flexible method, its downside is that\n",
      " |      using it can be quite a bit slower than using more specific methods\n",
      " |      like `agg` or `transform`. Pandas offers a wide range of method that will\n",
      " |      be much faster than using `apply` for their specific purposes, so try to\n",
      " |      use them before reaching for `apply`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          A callable that takes a dataframe as its first argument, and\n",
      " |          returns a dataframe, a series or a scalar. In addition the\n",
      " |          callable may take positional and keyword arguments.\n",
      " |      args, kwargs : tuple and dict\n",
      " |          Optional positional and keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      applied : Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pipe : Apply function to the full GroupBy object instead of to each\n",
      " |          group.\n",
      " |      aggregate : Apply aggregate function to the GroupBy object.\n",
      " |      transform : Apply function column-by-column to the GroupBy object.\n",
      " |      Series.apply : Apply a function to a Series.\n",
      " |      DataFrame.apply : Apply a function to each row or column of a DataFrame.\n",
      " |  \n",
      " |  get_group(self, name, obj=None)\n",
      " |      Constructs NDFrame from group with provided name.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object\n",
      " |          the name of the group to get as a DataFrame\n",
      " |      obj : NDFrame, default None\n",
      " |          the NDFrame to take the DataFrame out of.  If\n",
      " |          it is None, the object groupby was called on will\n",
      " |          be used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      group : same type as obj\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply a function `func` with arguments to this GroupBy object and return\n",
      " |      the function's result.\n",
      " |      \n",
      " |      .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      Use `.pipe` when you want to improve readability by chaining together\n",
      " |      functions that expect Series, DataFrames, GroupBy or Resampler objects.\n",
      " |      Instead of writing\n",
      " |      \n",
      " |      >>> h(g(f(df.groupby('group')), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.groupby('group')\n",
      " |      ...    .pipe(f)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(h, arg2=b, arg3=c))\n",
      " |      \n",
      " |      which is much more readable.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable or tuple of (callable, string)\n",
      " |          Function to apply to this GroupBy object or, alternatively,\n",
      " |          a `(callable, data_keyword)` tuple where `data_keyword` is a\n",
      " |          string indicating the keyword of `callable` that expects the\n",
      " |          GroupBy object.\n",
      " |      args : iterable, optional\n",
      " |             positional arguments passed into `func`.\n",
      " |      kwargs : dict, optional\n",
      " |               a dictionary of keyword arguments passed into `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of `func`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.pipe : Apply a function with arguments to a series.\n",
      " |      pandas.DataFrame.pipe: Apply a function with arguments to a dataframe.\n",
      " |      apply : Apply function to each group instead of to the\n",
      " |          full GroupBy object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See more `here\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/groupby.html#piping-function-calls>`_\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  1\n",
      " |      1  b  2\n",
      " |      2  a  3\n",
      " |      3  b  4\n",
      " |      \n",
      " |      To get the difference between each groups maximum and minimum value in one\n",
      " |      pass, you can do\n",
      " |      \n",
      " |      >>> df.groupby('A').pipe(lambda x: x.max() - x.min())\n",
      " |         B\n",
      " |      A\n",
      " |      a  2\n",
      " |      b  2\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.groupby.groupby._GroupBy:\n",
      " |  \n",
      " |  groups\n",
      " |      Dict {group name -> group labels}.\n",
      " |  \n",
      " |  indices\n",
      " |      Dict {group name -> group indices}.\n",
      " |  \n",
      " |  ngroups\n",
      " |  \n",
      " |  plot\n",
      " |      Class implementing the .plot attribute for groupby objects.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  ndim\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.core.groupby.DataFrameGroupBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
