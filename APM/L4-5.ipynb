{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live-Coding lesson on Markov chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll apply to text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = \"./divinacommedia_cleaned.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Familiarize with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_file, 'r', encoding='utf8') as infile:\n",
    "    for line in infile:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many words I find in my file?\n",
    "How many couples I need?\n",
    "\n",
    "I have 30 characters possible( 26 letters + space, newline, full stop, exlamation point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First order Chain\n",
    "30**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Second order Chain\n",
    "30**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#third order Chain\n",
    "30**4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need at leat 10e7 characters to make a good estimations of that order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our corpus we have .ca 5e5 characters: we can't do a good 2nd order estimation. But we know that not every combination is spread equally, some compbination doesn't occur at all!!! Most of the combination won't appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529771\n"
     ]
    }
   ],
   "source": [
    "letters=0\n",
    "with open(text_file, 'r', encoding='utf8') as infile:\n",
    "    for line in infile:\n",
    "        for letter in line:\n",
    "            letters +=1\n",
    "print(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many and which letters I actually have in my text\n",
    "from collections import Counter\n",
    "observed = Counter()\n",
    "with open(text_file, 'r', encoding='utf-8-sig') as infile:\n",
    "    for line in infile:\n",
    "        for letter in line:\n",
    "            observed[letter] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'N': 258,\n",
       "         'e': 46094,\n",
       "         'l': 23087,\n",
       "         ' ': 83019,\n",
       "         'm': 11681,\n",
       "         'z': 1848,\n",
       "         'o': 37254,\n",
       "         'd': 14599,\n",
       "         'c': 20267,\n",
       "         'a': 42035,\n",
       "         'i': 39200,\n",
       "         'n': 26229,\n",
       "         's': 22188,\n",
       "         't': 22478,\n",
       "         'r': 25805,\n",
       "         'v': 7946,\n",
       "         '\\n': 19053,\n",
       "         'p': 10790,\n",
       "         'u': 13408,\n",
       "         ',': 8513,\n",
       "         'h': 7109,\n",
       "         'é': 903,\n",
       "         '.': 3275,\n",
       "         'A': 377,\n",
       "         'q': 3025,\n",
       "         'è': 925,\n",
       "         'g': 7121,\n",
       "         'f': 4947,\n",
       "         '!': 232,\n",
       "         'T': 283,\n",
       "         '’': 7623,\n",
       "         'ù': 1080,\n",
       "         ';': 1628,\n",
       "         'b': 2758,\n",
       "         'ò': 938,\n",
       "         'I': 359,\n",
       "         'M': 405,\n",
       "         'à': 855,\n",
       "         'E': 586,\n",
       "         'ì': 1383,\n",
       "         'P': 473,\n",
       "         'Q': 328,\n",
       "         '«': 1062,\n",
       "         '»': 1062,\n",
       "         'R': 117,\n",
       "         ':': 988,\n",
       "         'ï': 427,\n",
       "         'ó': 30,\n",
       "         '?': 278,\n",
       "         'O': 356,\n",
       "         'V': 222,\n",
       "         'D': 407,\n",
       "         'C': 554,\n",
       "         'L': 411,\n",
       "         'S': 443,\n",
       "         'ë': 83,\n",
       "         '“': 51,\n",
       "         'B': 223,\n",
       "         '”': 51,\n",
       "         '—': 18,\n",
       "         '‘': 109,\n",
       "         'G': 199,\n",
       "         'F': 180,\n",
       "         'Z': 7,\n",
       "         'ü': 55,\n",
       "         'U': 43,\n",
       "         'H': 2,\n",
       "         'ö': 1,\n",
       "         'ä': 8,\n",
       "         'x': 3,\n",
       "         'y': 1,\n",
       "         '(': 3,\n",
       "         ')': 3,\n",
       "         'È': 2,\n",
       "         'j': 2,\n",
       "         'Ë': 2,\n",
       "         'Ï': 1,\n",
       "         '-': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can treat this wierd data as they are, or we can replace them in a certain way.\n",
    "We make a manual normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace = {'Ë':'E', 'Ï':'I',\n",
    "              'ö':'o', 'ä':'a',\n",
    "              'ü':'u', 'ë':'e',\n",
    "              'ï':'i' }\n",
    "\n",
    "def letter_normalization_naive(letter):\n",
    "    if letter in to_replace:\n",
    "        return to_replace[letter]\n",
    "    return letter\n",
    " \n",
    "def letter_normalization_short(letter):\n",
    "    return to_replace.get(letter, letter)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_normalization_naive('Ë')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_normalization_short('Ë')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 ns ± 7.28 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit letter_normalization_naive('Ë')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 ns ± 10.4 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit letter_normalization_short('Ë')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's slightly faster the naive version!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_normalization = letter_normalization_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many and which letters I actually have in my text\n",
    "from collections import Counter\n",
    "observed = Counter()\n",
    "with open(text_file, 'r', encoding='utf-8-sig') as infile:\n",
    "    for line in infile:\n",
    "        for letter in line:\n",
    "            modified_letter = letter_normalization(letter)\n",
    "            observed[modified_letter] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "completely random selection!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acua rrlu nrall\n",
      "aoht\n"
     ]
    }
   ],
   "source": [
    "letters = list(observed.keys())\n",
    "occurences = list(observed.values())\n",
    "generated = choices(letters, occurences, k =20 )\n",
    "\n",
    "collated = \"\".join(generated)\n",
    "print(collated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First order markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to take letters in couples.\n",
    "\n",
    "\"home\" -> (h,o), (o,m), (m,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('h', 'o'), ('o', 'm'), ('m', 'e')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def couples_from_seq(seq):\n",
    "    \"\"\"`seq` is a list of characters\"\"\"\n",
    "    return zip(seq, seq[1:])\n",
    "\n",
    "list(couples_from_seq('home'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick up all the divina commedia as a single string:\n",
    "\n",
    "### NOT MEMORY FRIENDLY!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_file, 'r', encoding='utf-8-sig') as infile:\n",
    "    whole_text = \"\".join(line for line in infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nel mezzo del cammin di nostra vita\n",
      "mi ritrovai per una selva oscura,\n",
      "ché la diritta via era smarrita.\n",
      "\n",
      "Ahi quanto a dir\n"
     ]
    }
   ],
   "source": [
    "print(whole_text[:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_couples = list(couples_from_seq(whole_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('N', 'e'),\n",
       " ('e', 'l'),\n",
       " ('l', ' '),\n",
       " (' ', 'm'),\n",
       " ('m', 'e'),\n",
       " ('e', 'z'),\n",
       " ('z', 'z'),\n",
       " ('z', 'o'),\n",
       " ('o', ' '),\n",
       " (' ', 'd')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_couples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# Counter -= defaultdict(int)\n",
    "#I think it's like a counter of counters\n",
    "couples_counter = defaultdict(Counter)\n",
    "for first_letter, second_letter in all_couples:\n",
    "    couples_counter[first_letter][second_letter] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 1, 'c': 1})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = defaultdict(Counter)\n",
    "foo['b']['a'] += 1\n",
    "foo['b']['c'] += 1\n",
    "\n",
    "#Is like:\n",
    "if 'c' not in foo:\n",
    "    foo['c'] = Counter()\n",
    "foo['c']['a'] += 1\n",
    "\n",
    "foo\n",
    "\n",
    "foo['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many actual couples did we observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529769"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(counts.values()) for counts in couples_counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'é'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter = 'N'\n",
    "possible_letters = list(couples_counter[letter].keys())\n",
    "counts = list(couples_counter[letter].values())\n",
    "choices(possible_letters, counts)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the simulation I need to repeat this procedure replacing the starting letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novo quttolom’l ciontre ’osa doneriose cate?».\n",
      "Tuto\n",
      "sara? oma lo quansa i.\n",
      "\n",
      "pe co toio v’,\n",
      "\n",
      "\n",
      "\n",
      "dinne,\n",
      "serisspo gntuammocerà «Ad sema;\n",
      "Magi sttona\n",
      "\n",
      "pi na\n",
      "Mato,\n",
      "No tr pi ra;\n",
      "Qunone ifi atugu r a di se sav\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    last_letter = text[-1]\n",
    "    possible_letters = list(couples_counter[last_letter].keys())\n",
    "    counts = list(couples_counter[last_letter].values())\n",
    "    next_letter = choices(possible_letters, counts)[0]\n",
    "    text.append(next_letter)\n",
    "print(\"\".join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second order Markov Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_file, 'r', encoding='utf-8-sig') as infile:\n",
    "    whole_text = \"\".join(line for line in infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplets_from_seq(seq):\n",
    "    \"\"\"`seq` is a list of characters\"\"\"\n",
    "    return zip(seq, seq[1:], seq[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_triplets = list(triplets_from_seq(whole_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('N', 'e', 'l'),\n",
       " ('e', 'l', ' '),\n",
       " ('l', ' ', 'm'),\n",
       " (' ', 'm', 'e'),\n",
       " ('m', 'e', 'z'),\n",
       " ('e', 'z', 'z'),\n",
       " ('z', 'z', 'o'),\n",
       " ('z', 'o', ' '),\n",
       " ('o', ' ', 'd'),\n",
       " (' ', 'd', 'e')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_triplets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# Counter -= defaultdict(int)\n",
    "#I think it's like a counter of counters\n",
    "triplets_counter = defaultdict(Counter)\n",
    "for first_letter, second_letter, third_letter in all_triplets:\n",
    "    triplets_counter[(first_letter,second_letter)][third_letter] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = tuple('Ne')\n",
    "possible_letters = list(triplets_counter[letters].keys())\n",
    "counts = list(triplets_counter[letters].values())\n",
    "choices(possible_letters, counts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('e', 'l')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['N', 'e', 'l']\n",
    "tuple(text[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['N', 'e', 'l']\n",
    "tuple(text[-2:])\n",
    "last_letters = tuple(text[-2:])\n",
    "possible_letters = list(triplets_counter[last_letters].keys())\n",
    "counts = list(triplets_counter[last_letters].values())\n",
    "choices(possible_letters, counts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nelle daredichia\n",
      "«Deh, di ver lor lio, Trantavanzi.\n",
      "\n",
      "Quemossanzia voi vol tutto\n",
      "quessi mil suoi to benimmina vosì, la ché qua che ma,\n",
      "d’udisal nomettaro aldant’ae questrospiartò che al perivane.\n",
      "\n",
      "e al q\n"
     ]
    }
   ],
   "source": [
    "text = ['N', 'e']\n",
    "for i in range(200):\n",
    "    last_letters = tuple(text[-2:])\n",
    "    possible_letters = list(triplets_counter[last_letters].keys())\n",
    "    counts = list(triplets_counter[last_letters].values())\n",
    "    next_letter = choices(possible_letters, counts)[0]\n",
    "    text.append(next_letter)\n",
    "print(\"\".join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markovian chain of order N\n",
    "\n",
    "It's not a masterpiece because the program create multiple copies of the text to merge them in a zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nel fosse.\n",
      "\n",
      "Ito è nostro\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from random import choices\n",
    "\n",
    "text_file = \"./divinacommedia_cleaned.txt\"\n",
    "with open(text_file, 'r', encoding='utf-8-sig') as infile:\n",
    "    whole_text = \"\".join(line for line in infile)\n",
    "    \n",
    "def n_tuples_from_seq(n, seq): \n",
    "    tuple_of_seq = tuple(seq[i:] for i in range(n))\n",
    "    return zip(*tuple_of_seq)\n",
    "\n",
    "def counts_from_seq(tuple_seq):\n",
    "    tuple_counter = defaultdict(Counter)\n",
    "    for *previuos_letters, last_letter in tuple_seq: #Separate the last element from the rest\n",
    "        tuple_counter[tuple(previuos_letters)][last_letter] +=1 #You can't use list as key for dictionaries\n",
    "    return tuple_counter\n",
    "\n",
    "\n",
    "    \n",
    "def generate_text(lenght, seed, n):\n",
    "    for i in range(lenght):\n",
    "        last_letters = tuple(text[-(n-1):])\n",
    "        possible_letters = list(tuples_counter[last_letters].keys())\n",
    "        counts = list(tuples_counter[last_letters].values())\n",
    "        next_letter = choices(possible_letters, counts)[0]\n",
    "        text.append(next_letter)\n",
    "    return text\n",
    "\n",
    "lenght = 10\n",
    "n=5\n",
    "seed = list(whole_text[:n-1])\n",
    "all_tuples = list(n_tuples_from_seq(n,whole_text))\n",
    "tuples_counter = counts_from_seq(all_tuples)\n",
    "text = generate_text(lenght, seed, n)\n",
    "print(\"\".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url_base = (\"https://raw.githubusercontent.com/UniboDIFABiophysics\"+\n",
    "                \"/programmingCourseDIFA/master/divine_comedy/\")\n",
    "filename = \"divinacommedia_cleaned.txt\"\n",
    "response = requests.get(url_base + filename)    \n",
    "response.raise_for_status()    \n",
    "with open(filename, 'wb') as handle:\n",
    "    handle.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation in a Class\n",
    "I would like to obtain an object that acts like that:\n",
    "```python\n",
    "whole_text = load_source()\n",
    "generator = TextGenerator(order = 3, split='letters')\n",
    "generator.learn(whole_text) #How many times I want\n",
    "generator.generate(seed='Nel', lenght=400)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotLearnedError(Exception):\n",
    "    pass\n",
    "\n",
    "class TextGenerator:\n",
    "    def __init__(self, order, split='letter'):\n",
    "        self._learned = False #Did I ever called the learn function\n",
    "        self.order = order\n",
    "        self.split = split\n",
    "        self.data = defaultdict(Counter)\n",
    "        \n",
    "    def _counts_from_seq(self, tuple_seq):\n",
    "        for *previuos_letters, last_letter in self.data: #Separate the last element from the rest\n",
    "            self.data[tuple(previuos_letters)][last_letter] +=1 #You can't use list as key for dictionaries\n",
    "\n",
    "    def _generate_text_tokens(self, text):\n",
    "        if self.split == 'letter':\n",
    "            return list(text)\n",
    "        elif self.split == 'word': #TODO: how to manage commas\n",
    "            return text.split(' ') \n",
    "        else:\n",
    "            raise ValueError(\"Splitting method not known\")\n",
    "            \n",
    "        \n",
    "    def learn(self, text):\n",
    "        tokens = self._generate_text_tokens(text)\n",
    "        all_tuples = list(n_tuples_from_seq(self.order,tokens))\n",
    "        self._counts_from_seq(all_tuples)\n",
    "        #We have learned something\n",
    "        self._learned = True\n",
    "        # fluent interface\n",
    "        return self\n",
    "    \n",
    "    def generate(self, seed, lenght):\n",
    "        \"\"\"\n",
    "        raises:\n",
    "        -------\n",
    "            `NotLearnedError` if the `self.learn` function has not been called before\n",
    "        \"\"\"\n",
    "        # Check that we perfomed the learn function\n",
    "        if not self._learned:\n",
    "            raise NotLearnedError()\n",
    "        output_text = generate_text(lenght = lenght,seed = seed, n=self.order)\n",
    "        return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-f9509e1e310f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'letters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhole_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#How many times I want\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Nel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlenght\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-8b8966df4bf8>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, seed, lenght)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlenght\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlenght\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlenght\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-16b3fd16110b>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(lenght, seed, n)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpossible_letters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_letters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_letters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mnext_letter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_letters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_letter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Ale/lib/python3.7/random.py\u001b[0m in \u001b[0;36mchoices\u001b[0;34m(self, population, weights, cum_weights, k)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The number of weights does not match the population'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mbisect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_bisect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbisect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcum_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcum_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         return [population[bisect(cum_weights, random() * total, 0, hi)]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "generator = TextGenerator(order = 3, split='letters')\n",
    "generator.learn(whole_text) #How many times I want\n",
    "generator.generate(seed='Nel', lenght=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fluent interface allows me to make those kind of sequential calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TextGenerator(order = 3).learn(whole_text).generate(seed='Nel', lenght=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "text_1 = load_divina_commedia()\n",
    "text_2 = load_decameron()\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
