Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	4	create_partials
	5

[Wed Mar 20 10:18:05 2019]
rule create_partials:
    output: partial_3.txt
    jobid: 3
    wildcards: number=3

[Wed Mar 20 10:18:05 2019]
rule create_partials:
    output: partial_4.txt
    jobid: 4
    wildcards: number=4

[Wed Mar 20 10:18:05 2019]
rule create_partials:
    output: partial_2.txt
    jobid: 2
    wildcards: number=2

[Wed Mar 20 10:18:05 2019]
rule create_partials:
    output: partial_1.txt
    jobid: 1
    wildcards: number=1

[Wed Mar 20 10:18:05 2019]
Finished job 3.
1 of 5 steps (20%) done
[Wed Mar 20 10:18:05 2019]
Finished job 2.
2 of 5 steps (40%) done
[Wed Mar 20 10:18:05 2019]
Finished job 4.
3 of 5 steps (60%) done
[Wed Mar 20 10:18:05 2019]
Finished job 1.
4 of 5 steps (80%) done

[Wed Mar 20 10:18:05 2019]
rule all:
    input: partial_1.txt, partial_2.txt, partial_3.txt, partial_4.txt
    output: result.txt
    jobid: 0

[Wed Mar 20 10:18:05 2019]
Finished job 0.
5 of 5 steps (100%) done
Complete log: /home/alessandro/Python/snakemake_lesson/.snakemake/log/2019-03-20T101805.291580.snakemake.log
